{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\git\\ekostat_calculator\n"
     ]
    }
   ],
   "source": [
    "# Reload when code changed:\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd\n",
    "import sys\n",
    "import os\n",
    "path = \"../\"\n",
    "sys.path.append(path)\n",
    "#os.path.abspath(\"../\")\n",
    "print(os.path.abspath(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\core\\__init__.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.20.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import core\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(core) \n",
    "try:\n",
    "    logging.shutdown()\n",
    "    importlib.reload(logging)\n",
    "except:\n",
    "    pass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "from event_handler import EventHandler\n",
    "from event_handler import get_list_from_interval\n",
    "print(core.__file__)\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:07:40,208\tlogger.py\t85\tadd_log\tDEBUG\t\n",
      "2018-09-19 17:07:40,216\tlogger.py\t86\tadd_log\tDEBUG\t========================================================================================================================\n",
      "2018-09-19 17:07:40,221\tlogger.py\t87\tadd_log\tDEBUG\t### Log added for log_id \"event_handler\" at locaton: ..\\log\\main_event_handler.log\n",
      "2018-09-19 17:07:40,224\tlogger.py\t88\tadd_log\tDEBUG\t------------------------------------------------------------------------------------------------------------------------\n",
      "2018-09-19 17:07:40,231\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:07:40,235\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../\n",
      "====================================================================================================\n",
      "event_handler\n",
      "..//log\n",
      "main\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:07:41,253\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 1.0180583000183105\n",
      "2018-09-19 17:07:41,308\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 1.1020631790161133\n",
      "2018-09-19 17:07:41,315\tevent_handler.py\t48\tf\tDEBUG\tStart: \"test_timer\"\n",
      "2018-09-19 17:07:42,319\tevent_handler.py\t52\tf\tDEBUG\tStop: \"test_timer\". Time for running method was 0.9970569610595703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "user_id_1 = 'user_1'\n",
    "user_id_2 = 'user_2'\n",
    "user_1_ws_1 = 'mw1'\n",
    "print(path)\n",
    "paths = {'user_id': user_id_1, \n",
    "         'workspace_directory': 'D:/git/ekostat_calculator/workspaces', \n",
    "         'resource_directory': path + '/resources', \n",
    "         'log_directory': path + '/log', \n",
    "         'test_data_directory': path + '/test_data', \n",
    "         'temp_directory': path + '/temp'}\n",
    "\n",
    "ekos = EventHandler(**paths)\n",
    "ekos.test_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_workspace_uuid_in_test_requests(workspace_alias='New test workspace'):\n",
    "    ekos = EventHandler(**paths)\n",
    "\n",
    "    workspace_uuid = ekos.get_unique_id_for_alias(workspace_alias=workspace_alias)\n",
    "   \n",
    "    if workspace_uuid: \n",
    "        print('Updating user {} with uuid: {}'.format(user_id_1, workspace_uuid))\n",
    "        print('-'*70)\n",
    "        ekos.update_workspace_uuid_in_test_requests(workspace_uuid)\n",
    "    else:\n",
    "        print('No workspaces for user: {}'.format(user_id_1))\n",
    "        \n",
    "\n",
    "        \n",
    "def update_subset_uuid_in_test_requests(workspace_alias='New test workspace', \n",
    "                                        subset_alias=False):\n",
    "    ekos = EventHandler(**paths)\n",
    "\n",
    "    workspace_uuid = ekos.get_unique_id_for_alias(workspace_alias=workspace_alias)\n",
    "    \n",
    "    if workspace_uuid:              \n",
    "        ekos.load_workspace(workspace_uuid)\n",
    "        subset_uuid = ekos.get_unique_id_for_alias(workspace_alias=workspace_alias, subset_alias=subset_alias)\n",
    "        print('Updating user {} with workspace_uuid {} and subset_uuid {}'.format(user_id_1, workspace_uuid, subset_uuid))\n",
    "        print(workspace_uuid, subset_uuid)\n",
    "        print('-'*70)\n",
    "        ekos.update_subset_uuid_in_test_requests(subset_uuid=subset_uuid)\n",
    "    else:\n",
    "        print('No workspaces for user: {}'.format(user_id_1))\n",
    "        \n",
    "\n",
    "        \n",
    "def print_boolean_structure(workspace_uuid): \n",
    "    workspace_object = ekos.get_workspace(unique_id=workspace_uuid) \n",
    "    workspace_object.index_handler.print_boolean_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update_workspace_uuid_in_test_requests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request workspace add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:07:46,698\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:07:46,702\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:07:47,600\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.8990514278411865\n",
      "2018-09-19 17:07:47,638\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 0.9410538673400879\n",
      "2018-09-19 17:07:47,652\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_workspace_add\"\n",
      "2018-09-19 17:07:47,659\tevent_handler.py\t3965\trequest_workspace_add\tDEBUG\tStart: request_workspace_add\n",
      "2018-09-19 17:07:47,687\tevent_handler.py\t414\tcopy_workspace\tDEBUG\tTrying to copy workspace \"default_workspace\". Copy has alias \"New test workspace\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¤ New test workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:07:47,886\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:07:48,047\tlogger.py\t85\tadd_log\tDEBUG\t\n",
      "2018-09-19 17:07:48,052\tlogger.py\t86\tadd_log\tDEBUG\t========================================================================================================================\n",
      "2018-09-19 17:07:48,057\tlogger.py\t87\tadd_log\tDEBUG\t### Log added for log_id \"default_subset\" at locaton: D:\\git\\ekostat_calculator\\workspaces\\e7fbd04c-2be5-497d-88ae-af33860580ca\\log\\subset_default_subset.log\n",
      "2018-09-19 17:07:48,065\tlogger.py\t88\tadd_log\tDEBUG\t------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "default_subset\n",
      "D:/git/ekostat_calculator/workspaces/e7fbd04c-2be5-497d-88ae-af33860580ca/log\n",
      "subset\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:07:48,481\tlogger.py\t85\tadd_log\tDEBUG\t\n",
      "2018-09-19 17:07:48,488\tlogger.py\t86\tadd_log\tDEBUG\t========================================================================================================================\n",
      "2018-09-19 17:07:48,496\tlogger.py\t87\tadd_log\tDEBUG\t### Log added for log_id \"e7fbd04c-2be5-497d-88ae-af33860580ca\" at locaton: D:\\git\\ekostat_calculator\\workspaces\\e7fbd04c-2be5-497d-88ae-af33860580ca\\log\\workspace_e7fbd04c-2be5-497d-88ae-af33860580ca.log\n",
      "2018-09-19 17:07:48,502\tlogger.py\t88\tadd_log\tDEBUG\t------------------------------------------------------------------------------------------------------------------------\n",
      "2018-09-19 17:07:48,512\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n",
      "2018-09-19 17:07:48,526\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_workspace_add\". Time for running method was 0.8670494556427002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "e7fbd04c-2be5-497d-88ae-af33860580ca\n",
      "D:/git/ekostat_calculator/workspaces/e7fbd04c-2be5-497d-88ae-af33860580ca/log\n",
      "workspace\n",
      "----------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Time for request: 1.8381049633026123\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "ekos = EventHandler(**paths)\n",
    "request = ekos.test_requests['request_workspace_add_1']\n",
    "response_workspace_add = ekos.request_workspace_add(request)\n",
    "ekos.write_test_response('request_workspace_add_1', response_workspace_add)\n",
    "\n",
    "# request = ekos.test_requests['request_workspace_add_2']\n",
    "# response_workspace_add = ekos.request_workspace_add(request)\n",
    "# ekos.write_test_response('request_workspace_add_2', response_workspace_add)\n",
    "print('-'*50)\n",
    "print('Time for request: {}'.format(time.time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update workspace uuid in test requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:07:49,169\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:07:49,172\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:07:50,223\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 1.0510599613189697\n",
      "2018-09-19 17:07:50,262\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 1.093062400817871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating user user_1 with uuid: e7fbd04c-2be5-497d-88ae-af33860580ca\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "update_workspace_uuid_in_test_requests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Request workspace import default data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ekos = EventHandler(**paths)\n",
    "# # When copying data the first time all sources has status=0, i.e. no data will be loaded. \n",
    "# request = ekos.test_requests['request_workspace_import_default_data']\n",
    "# response_import_data = ekos.request_workspace_import_default_data(request)\n",
    "# ekos.write_test_response('request_workspace_import_default_data', response_import_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from sharkweb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:07:54,307\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:07:54,310\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:07:55,265\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.955054521560669\n",
      "2018-09-19 17:07:55,311\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 1.0050575733184814\n",
      "2018-09-19 17:07:55,319\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_sharkweb_import\"\n",
      "2018-09-19 17:07:55,380\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== e7fbd04c-2be5-497d-88ae-af33860580ca\n",
      "{'year_from': 2011, 'year_to': 2011, 'datatype': 'Physical and Chemical', 'water_district_list': ['Västerhavets vattendistrikt'], 'type_area_list': [], 'svar_sea_area_list': [], 'encoding': 'utf8', 'lineend': 'windows', 'delimiters': 'point-tab', 'sample_table_view': 'sample_col_physicalchemical_columnparams', 'parameter': None, 'headerlang': 'internal'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:07:55,867\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Status:  200\n",
      "DEBUG: Header:  application/json; charset=utf-8\n",
      "DEBUG: Encoding:  utf-8\n",
      "DEBUG: Status:  200\n",
      "DEBUG: Header:  application/json; charset=utf-8\n",
      "DEBUG: Encoding:  utf-8\n",
      "DEBUG: Status:  200\n",
      "DEBUG: Header:  application/json; charset=utf-8\n",
      "DEBUG: Encoding:  utf-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:07:58,485\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_sharkweb_import\". Time for running method was 3.1581807136535645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Status:  200\n",
      "DEBUG: Header:  application/octet-stream; charset=utf-8\n",
      "DEBUG: Encoding:  utf-8\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "ekos = EventHandler(**paths)\n",
    "request = ekos.test_requests['request_sharkweb_import']\n",
    "response_sharkweb_import = ekos.request_sharkweb_import(request)\n",
    "ekos.write_test_response('request_sharkweb_import', response_sharkweb_import)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adv_check_status': '',\n",
       " 'adv_checked_by_list': '',\n",
       " 'adv_dataset_name': '',\n",
       " 'adv_dataset_name_option': '',\n",
       " 'adv_datatype_list': '',\n",
       " 'adv_deliverer_list': '',\n",
       " 'adv_max_depth': '',\n",
       " 'adv_min_depth': '',\n",
       " 'adv_orderer_list': '',\n",
       " 'adv_parameter_list': '',\n",
       " 'adv_project_list': '',\n",
       " 'adv_quality_flag_list': '',\n",
       " 'adv_red_list_category': '',\n",
       " 'bounds': '',\n",
       " 'county_list': '',\n",
       " 'datatype': 'Physical and Chemical',\n",
       " 'delimiters': 'point-tab',\n",
       " 'economic_zone': '',\n",
       " 'encoding': 'utf8',\n",
       " 'headerlang': 'internal',\n",
       " 'helcom_ospar': '',\n",
       " 'lineend': 'windows',\n",
       " 'month_list': '',\n",
       " 'municipality_list': '',\n",
       " 'parameter': None,\n",
       " 'sample_table_view': 'sample_col_physicalchemical_columnparams',\n",
       " 'sea_basin': '',\n",
       " 'station_name': '',\n",
       " 'station_name_option': '',\n",
       " 'svar_sea_area_list': '',\n",
       " 'taxon_name': '',\n",
       " 'taxon_name_option': '',\n",
       " 'type_area_list': '',\n",
       " 'water_category': '',\n",
       " 'water_district_list': 'V%C3%A4sterhavets%20vattendistrikt',\n",
       " 'year_from': 2011,\n",
       " 'year_to': 2011}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ekos.data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Physical and Chemical': {'datatype': 'Physical and Chemical',\n",
       "  'delimiters': 'point-tab',\n",
       "  'encoding': 'utf8',\n",
       "  'headerlang': 'internal',\n",
       "  'lineend': 'windows',\n",
       "  'parameter': None,\n",
       "  'sample_table_view': 'sample_col_physicalchemical_columnparams',\n",
       "  'svar_sea_area_list': [],\n",
       "  'type_area_list': [],\n",
       "  'water_district_list': ['Västerhavets vattendistrikt'],\n",
       "  'year_from': 2011,\n",
       "  'year_to': 2011}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ekos.selection_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ekos = EventHandler(**paths)\n",
    "# ekos.mapping_objects['sharkweb_mapping'].df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request data source list/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:08:04,302\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:08:04,306\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:08:05,439\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 1.1330649852752686\n",
      "2018-09-19 17:08:05,492\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 1.190068006515503\n",
      "2018-09-19 17:08:05,499\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_workspace_data_sources_list\"\n",
      "2018-09-19 17:08:05,507\tevent_handler.py\t4188\trequest_workspace_data_sources_list\tDEBUG\tStart: request_workspace_data_sources_list\n",
      "2018-09-19 17:08:05,564\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:08:06,068\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n",
      "2018-09-19 17:08:06,077\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_workspace_data_sources_list\". Time for running method was 0.5690326690673828\n",
      "2018-09-19 17:08:06,083\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_workspace_data_sources_edit\"\n",
      "2018-09-19 17:08:06,086\tevent_handler.py\t4146\trequest_workspace_data_sources_edit\tDEBUG\tStart: request_workspace_data_sources_list\n",
      "2018-09-19 17:08:06,124\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:08:06,166\tworkspaces.py\t1832\tload_all_data\tDEBUG\tAll selected data in (status 1 in datatype_settings.txt) is not loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST True physicalchemical_sharkweb_data_all_2011-2011_201809191707.txt\n",
      "¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤¤\n",
      "D:/git/ekostat_calculator/workspaces/e7fbd04c-2be5-497d-88ae-af33860580ca/input_data/exports\\all_data.pkl\n",
      "D:/git/ekostat_calculator/workspaces/e7fbd04c-2be5-497d-88ae-af33860580ca/input_data/exports\\all_data.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:08:06,936\tworkspaces.py\t1915\tload_datatype_data\tDEBUG\tNew data files has been loaded for datatype: physicalchemical\n",
      "2018-09-19 17:08:06,986\tworkspaces.py\t1915\tload_datatype_data\tDEBUG\tNew data files has been loaded for datatype: physicalchemicalmodel\n",
      "2018-09-19 17:08:07,075\tworkspaces.py\t1915\tload_datatype_data\tDEBUG\tNew data files has been loaded for datatype: chlorophyll\n",
      "2018-09-19 17:08:07,121\tworkspaces.py\t1915\tload_datatype_data\tDEBUG\tNew data files has been loaded for datatype: phytoplankton\n",
      "2018-09-19 17:08:07,178\tworkspaces.py\t1915\tload_datatype_data\tDEBUG\tNew data files has been loaded for datatype: zoobenthos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.all_data 0\n",
      "MMMMMMMMM\n",
      "time for _add_prioritized_parameter SALT is: 0.07000398635864258\n",
      "time for _add_prioritized_parameter TEMP is: 0.06900405883789062\n",
      "time for _add_prioritized_parameter DOXY is: 0.07000398635864258\n",
      "--------------------------------------------------\n",
      "Total time: 1.0900623798370361\n",
      "time_preparations              0.006000518798828125\n",
      "time_list_group_data:          0.006000041961669922\n",
      "time_list_calc_integ:          0.014000177383422852\n",
      "time_list_add_row:             0.5720319747924805\n",
      "time_all_calculations:         0.9990570545196533\n",
      "time_iterator:                 0.0\n",
      "time_add_data:                 0.07900476455688477\n",
      "Done adding integrated_calc \"CPHL_INTEG_CALC\" using parameter \"CPHL_BTL\"\n",
      "time for integrated_calc \"CPHL_INTEG_CALC\" using parameter \"CPHL_BTL is: 1.0900623798370361\n",
      "Saving data to: D:/git/ekostat_calculator/workspaces/e7fbd04c-2be5-497d-88ae-af33860580ca/input_data/exports/all_data.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:08:09,762\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_workspace_data_sources_list\"\n",
      "2018-09-19 17:08:09,765\tevent_handler.py\t4188\trequest_workspace_data_sources_list\tDEBUG\tStart: request_workspace_data_sources_list\n",
      "2018-09-19 17:08:09,808\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:08:09,820\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_workspace_data_sources_list\". Time for running method was 0.05500316619873047\n",
      "2018-09-19 17:08:09,824\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_workspace_data_sources_edit\". Time for running method was 3.7382137775421143\n"
     ]
    }
   ],
   "source": [
    "ekos = EventHandler(**paths)\n",
    "request = ekos.test_requests['request_workspace_data_sources_list']\n",
    "response = ekos.request_workspace_data_sources_list(request) \n",
    "ekos.write_test_response('request_workspace_data_sources_list', response) \n",
    "\n",
    "request = response\n",
    "request['data_sources'][0]['status'] = True \n",
    "# request['data_sources'][1]['status'] = True \n",
    "# request['data_sources'][2]['status'] = True \n",
    "\n",
    "\n",
    "# Edit data source \n",
    "response = ekos.request_workspace_data_sources_edit(request) \n",
    "ekos.write_test_response('request_workspace_data_sources_edit', response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_sources': [{'datatype': 'physicalchemical',\n",
       "   'filename': 'physicalchemical_sharkweb_data_all_2013-2017_201809190701.txt',\n",
       "   'loaded': False,\n",
       "   'status': True},\n",
       "  {'datatype': 'chlorophyll',\n",
       "   'filename': 'chlorophyll_sharkweb_data_Chlorophyll-a_2013-2017_201809190701.txt',\n",
       "   'loaded': False,\n",
       "   'status': True}],\n",
       " 'workspace_uuid': '77d1c01d-a150-4bf7-9572-92eb05e29bb4'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_sources': [{'datatype': 'physicalchemical',\n",
       "   'filename': 'physicalchemical_sharkweb_data_all_2013-2017_201809190701.txt',\n",
       "   'loaded': True,\n",
       "   'status': True},\n",
       "  {'datatype': 'chlorophyll',\n",
       "   'filename': 'chlorophyll_sharkweb_data_Chlorophyll-a_2013-2017_201809190701.txt',\n",
       "   'loaded': True,\n",
       "   'status': True}],\n",
       " 'workspace_uuid': '77d1c01d-a150-4bf7-9572-92eb05e29bb4'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4]\n",
      "[6, 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [1,2,3,4]\n",
    "y = [np.nan, 6, np.nan, 9]\n",
    "nx = []\n",
    "ny = []\n",
    "for xx, yy in zip(x, y):\n",
    "    if not np.isnan(yy):\n",
    "        nx.append(xx)\n",
    "        ny.append(yy)\n",
    "x, y = nx, ny\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request subset add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:11,827\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:29:11,827\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:29:12,587\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.7600009441375732\n",
      "2018-09-19 17:29:12,607\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 0.7800009250640869\n",
      "2018-09-19 17:29:12,617\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_subset_add\"\n",
      "2018-09-19 17:29:12,617\tevent_handler.py\t3116\trequest_subset_add\tDEBUG\tStart: request_subset_add\n",
      "2018-09-19 17:29:12,647\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:29:13,077\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n",
      "2018-09-19 17:29:13,087\tevent_handler.py\t367\tcopy_subset\tDEBUG\tTrying to copy subset \"default_subset\"\n",
      "2018-09-19 17:29:13,087\tworkspaces.py\t1405\tcopy_subset\tDEBUG\tCould not add subset with alias \"mw_subset\". Subset already exists!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¤ mw_subset\n"
     ]
    },
    {
     "ename": "SubsetAlreadyExists",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSubsetAlreadyExists\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c88575ad9e7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mekos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEventHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mekos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_requests\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'request_subset_add_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresponse_subset_add\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mekos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_subset_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mekos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_test_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'request_subset_add_1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse_subset_add\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git\\ekostat_calculator\\event_handler.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Start: \"{.__name__}\"'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mfrom_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mrv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mto_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stop: \"{.__name__}\". Time for running method was {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_time\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfrom_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git\\ekostat_calculator\\event_handler.py\u001b[0m in \u001b[0;36mrequest_subset_add\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   3125\u001b[0m         return_dict = self.copy_subset(workspace_uuid=workspace_uuid, \n\u001b[0;32m   3126\u001b[0m                                        \u001b[0msubset_source_uuid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset_uuid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3127\u001b[1;33m                                        subset_target_alias=new_alias)\n\u001b[0m\u001b[0;32m   3128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemp_return_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git\\ekostat_calculator\\event_handler.py\u001b[0m in \u001b[0;36mcopy_subset\u001b[1;34m(self, workspace_uuid, subset_source_uuid, subset_target_alias)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trying to copy subset \"{}\"'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset_source_uuid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;31m#        try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworkspace_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_subset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset_source_uuid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset_target_alias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;31m#        except:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;31m#            raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\git\\ekostat_calculator\\core\\workspaces.py\u001b[0m in \u001b[0;36mcopy_subset\u001b[1;34m(self, source_uuid, target_alias)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtarget_uuid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Could not add subset with alias \"{}\". Subset already exists!'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_alias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSubsetAlreadyExists\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1407\u001b[0m \u001b[1;31m#            return False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSubsetAlreadyExists\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ekos = EventHandler(**paths)\n",
    "request = ekos.test_requests['request_subset_add_1']\n",
    "response_subset_add = ekos.request_subset_add(request)\n",
    "ekos.write_test_response('request_subset_add_1', response_subset_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:15,909\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:29:15,919\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:29:16,679\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.7600009441375732\n",
      "2018-09-19 17:29:16,709\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 0.8000011444091797\n",
      "2018-09-19 17:29:16,729\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:29:17,169\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating user user_1 with workspace_uuid e7fbd04c-2be5-497d-88ae-af33860580ca and subset_uuid a8efce6c-25bc-48e2-8048-13a51d983fdb\n",
      "e7fbd04c-2be5-497d-88ae-af33860580ca a8efce6c-25bc-48e2-8048-13a51d983fdb\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "update_subset_uuid_in_test_requests(subset_alias='mw_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request subset get data filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:18,939\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:29:18,939\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:29:19,689\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.7500011920928955\n",
      "2018-09-19 17:29:19,719\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 0.780001163482666\n",
      "2018-09-19 17:29:19,729\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:29:19,729\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:29:20,469\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.7400009632110596\n",
      "2018-09-19 17:29:20,489\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 0.7600009441375732\n",
      "2018-09-19 17:29:20,529\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:29:20,959\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n",
      "2018-09-19 17:29:21,149\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_subset_get_data_filter\"\n",
      "2018-09-19 17:29:21,149\tevent_handler.py\t3309\trequest_subset_get_data_filter\tDEBUG\tStart: request_subset_get_data_filter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating user user_1 with workspace_uuid e7fbd04c-2be5-497d-88ae-af33860580ca and subset_uuid a8efce6c-25bc-48e2-8048-13a51d983fdb\n",
      "e7fbd04c-2be5-497d-88ae-af33860580ca a8efce6c-25bc-48e2-8048-13a51d983fdb\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:21,189\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:29:21,629\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n",
      "2018-09-19 17:29:21,669\tworkspaces.py\t1840\tload_all_data\tDEBUG\tData has been loaded from existing all_data.pickle file.\n",
      "2018-09-19 17:29:21,819\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_subset_get_data_filter\". Time for running method was 0.6700010299682617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.all_data 0\n",
      "TYPE AREA 1n\n",
      "TYPE AREA 1s\n",
      "TYPE AREA 2\n",
      "TYPE AREA 3\n",
      "TYPE AREA 4\n",
      "TYPE AREA 5\n"
     ]
    }
   ],
   "source": [
    "ekos = EventHandler(**paths)\n",
    "update_subset_uuid_in_test_requests(subset_alias='mw_subset')\n",
    "request = ekos.test_requests['request_subset_get_data_filter']\n",
    "response_subset_get_data_filter = ekos.request_subset_get_data_filter(request)\n",
    "ekos.write_test_response('request_subset_get_data_filter', response_subset_get_data_filter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# string = \"\"\"{\n",
    "#     \"workspace_uuid\": \"52725df4-b4a0-431c-a186-5e542fc6a3a4\",\n",
    "#     \"data_sources\": [\n",
    "#         {\n",
    "#             \"status\": true,\n",
    "#             \"loaded\": false,\n",
    "#             \"filename\": \"physicalchemical_sharkweb_data_all_2013-2014_20180916.txt\",\n",
    "#             \"datatype\": \"physicalchemical\"\n",
    "#         }\n",
    "#     ]\n",
    "# }\"\"\"\n",
    "\n",
    "# r = re.sub('\"workspace_uuid\": \".{36}\"', '\"workspace_uuid\": \"new\"', string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Request subset set data filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:22,599\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:29:22,599\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:29:23,369\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.7700011730194092\n",
      "2018-09-19 17:29:23,399\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 0.8000011444091797\n",
      "2018-09-19 17:29:23,409\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:29:23,409\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:29:24,219\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.8100011348724365\n",
      "2018-09-19 17:29:24,249\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 0.840001106262207\n",
      "2018-09-19 17:29:24,279\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:29:24,799\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating user user_1 with workspace_uuid e7fbd04c-2be5-497d-88ae-af33860580ca and subset_uuid a8efce6c-25bc-48e2-8048-13a51d983fdb\n",
      "e7fbd04c-2be5-497d-88ae-af33860580ca a8efce6c-25bc-48e2-8048-13a51d983fdb\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:25,019\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_subset_set_data_filter\"\n",
      "2018-09-19 17:29:25,029\tevent_handler.py\t3203\trequest_subset_set_data_filter\tDEBUG\tStart: request_subset_get_indicator_settings\n",
      "2018-09-19 17:29:25,059\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:29:25,571\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n",
      "2018-09-19 17:29:25,631\tworkspaces.py\t1840\tload_all_data\tDEBUG\tData has been loaded from existing all_data.pickle file.\n",
      "2018-09-19 17:29:25,701\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_subset_set_data_filter\". Time for running method was 0.6720035076141357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.all_data 0\n"
     ]
    }
   ],
   "source": [
    "ekos = EventHandler(**paths)\n",
    "update_subset_uuid_in_test_requests(subset_alias='mw_subset')\n",
    "request = ekos.test_requests['request_subset_set_data_filter']\n",
    "response_subset_set_data_filter = ekos.request_subset_set_data_filter(request)\n",
    "ekos.write_test_response('request_subset_set_data_filter', response_subset_set_data_filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request subset get indicator settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:26,115\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:29:26,125\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:29:26,895\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.7700011730194092\n",
      "2018-09-19 17:29:26,925\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 0.8100011348724365\n",
      "2018-09-19 17:29:26,935\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_subset_get_indicator_settings\"\n",
      "2018-09-19 17:29:26,935\tevent_handler.py\t3371\trequest_subset_get_indicator_settings\tDEBUG\tStart: request_subset_get_indicator_settings\n",
      "2018-09-19 17:29:26,965\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:29:27,435\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n",
      "2018-09-19 17:29:27,495\tworkspaces.py\t1840\tload_all_data\tDEBUG\tData has been loaded from existing all_data.pickle file.\n",
      "2018-09-19 17:29:27,545\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:27,635\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.all_data 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:27,715\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:27,795\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:27,875\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:27,939\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,009\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,089\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,149\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,219\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,289\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,359\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,429\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,489\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,569\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,629\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,699\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,769\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,839\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,909\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:28,969\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:29,049\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:29,119\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:29,189\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:29,219\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_subset_get_indicator_settings\". Time for running method was 2.284003496170044\n"
     ]
    }
   ],
   "source": [
    "ekos = EventHandler(**paths)\n",
    "request = ekos.test_requests['request_subset_get_indicator_settings']\n",
    "# request = ekos.test_requests['request_subset_get_indicator_settings_no_areas']\n",
    "# print(request['subset']['subset_uuid'])\n",
    "# request['subset']['subset_uuid'] = 'fel'\n",
    "# print(request['subset']['subset_uuid'])\n",
    "\n",
    "response_subset_get_indicator_settings = ekos.request_subset_get_indicator_settings(request)\n",
    "ekos.write_test_response('request_subset_get_indicator_settings', response_subset_get_indicator_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request subset set indicator settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ekos = EventHandler(**paths)\n",
    "request = ekos.test_requests['request_subset_set_indicator_settings']\n",
    "response_subset_set_indicator_settings = ekos.request_subset_set_indicator_settings(request)\n",
    "ekos.write_test_response('request_subset_set_indicator_settings', response_subset_set_indicator_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request subset calculate status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:47,122\tevent_handler.py\t109\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 17:29:47,122\tevent_handler.py\t144\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 17:29:47,902\tevent_handler.py\t120\t__init__\tDEBUG\tTime for mapping: 0.780001163482666\n",
      "2018-09-19 17:29:47,932\tevent_handler.py\t125\t__init__\tDEBUG\tTime for initiating EventHandler: 0.8100011348724365\n",
      "2018-09-19 17:29:47,932\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_subset_calculate_status\"\n",
      "2018-09-19 17:29:47,942\tevent_handler.py\t3156\trequest_subset_calculate_status\tDEBUG\tStart: request_subset_calculate_status\n",
      "2018-09-19 17:29:47,972\tevent_handler.py\t2845\tload_workspace\tDEBUG\tTrying to load new workspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\"\n",
      "2018-09-19 17:29:48,402\tevent_handler.py\t2863\tload_workspace\tINFO\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace loaded.\"\n",
      "2018-09-19 17:29:48,452\tworkspaces.py\t1840\tload_all_data\tDEBUG\tData has been loaded from existing all_data.pickle file.\n",
      "2018-09-19 17:29:48,482\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:48,512\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "2018-09-19 17:29:48,572\tevent_handler.py\t2856\tload_workspace\tDEBUG\tWorkspace \"e7fbd04c-2be5-497d-88ae-af33860580ca\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.all_data 0\n",
      "no waterbodies in filtered data\n",
      "QualityElementBase\n",
      "********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 17:29:48,622\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_subset_calculate_status\". Time for running method was 0.6800007820129395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nutrients\n",
      "QualityElementBase\n",
      "********\n",
      "phytoplankton\n"
     ]
    }
   ],
   "source": [
    "ekos = EventHandler(**paths)\n",
    "request = ekos.test_requests['request_subset_calculate_status']\n",
    "response = ekos.request_subset_calculate_status(request)\n",
    "ekos.write_test_response('request_subset_calculate_status', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request subset result get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-19 11:55:05,511\tevent_handler.py\t107\t__init__\tDEBUG\tStart EventHandler: event_handler\n",
      "2018-09-19 11:55:05,511\tevent_handler.py\t142\t_load_mapping_objects\tDEBUG\tLoading mapping files from pickle file.\n",
      "2018-09-19 11:55:06,181\tevent_handler.py\t118\t__init__\tDEBUG\tTime for mapping: 0.6700007915496826\n",
      "2018-09-19 11:55:06,201\tevent_handler.py\t123\t__init__\tDEBUG\tTime for initiating EventHandler: 0.6900007724761963\n",
      "2018-09-19 11:55:06,211\tevent_handler.py\t48\tf\tDEBUG\tStart: \"request_workspace_result\"\n",
      "2018-09-19 11:55:06,241\tevent_handler.py\t2771\tload_workspace\tDEBUG\tTrying to load new workspace \"67338c55-e72a-485f-a39c-f27ac6ec2256\" with alias \"New test workspace\"\n",
      "2018-09-19 11:55:06,631\tevent_handler.py\t2789\tload_workspace\tINFO\tWorkspace \"67338c55-e72a-485f-a39c-f27ac6ec2256\" with alias \"New test workspace loaded.\"\n",
      "2018-09-19 11:55:06,671\tevent_handler.py\t2782\tload_workspace\tDEBUG\tWorkspace \"67338c55-e72a-485f-a39c-f27ac6ec2256\" with alias \"New test workspace\" is already loaded. Set reload=True if you want to reload the workspace.\n",
      "..\\event_handler.py:1701: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['date'] = pd.to_datetime(df['SDATE'])\n",
      "..\\event_handler.py:1702: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df.sort_values('date', inplace=True)\n",
      "2018-09-19 11:56:23,216\tevent_handler.py\t52\tf\tDEBUG\tStop: \"request_workspace_result\". Time for running method was 77.00532269477844\n"
     ]
    }
   ],
   "source": [
    "ekos = EventHandler(**paths) \n",
    "request = ekos.test_requests['request_workspace_result']\n",
    "response_workspace_result = ekos.request_workspace_result(request)\n",
    "ekos.write_test_response('request_workspace_result', response_workspace_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\event_handler.py:1701: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "workspace_uuid = '67338c55-e72a-485f-a39c-f27ac6ec2256'\n",
    "subset_uuid = 'd8db1fa6-1ba1-4b5f-82a2-effd58716432'\n",
    "result = ekos.dict_data_timeseries(workspace_uuid=workspace_uuid, \n",
    "                                  subset_uuid=subset_uuid, \n",
    "                                  element_id='indicator_din_winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = result['indicator_din_winter-by_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.144208\n",
       "1    2.878750\n",
       "2    2.878750\n",
       "3    2.878750\n",
       "Name: HG_VALUE_LIMIT, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HG_VALUE_LIMIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2011-01-19 00:00:00'),\n",
       " Timestamp('2011-02-09 00:00:00'),\n",
       " Timestamp('2012-01-10 00:00:00'),\n",
       " Timestamp('2013-01-08 00:00:00')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pd.to_datetime(df['SDATE']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
